{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**qAIntum.ai**\n",
    "\n",
    "# **Quantum Neural Network (QNN) Classifier**\n",
    "\n",
    "This note is an example of using Photonic Analog (PA) QNN for binary classification. This is an application of the original work [\"Continuous Variable Quantum Neural Networks\"](https://arxiv.org/abs/1806.06871).\n",
    "\n",
    "Compared to Classical Neural Networks, PA QNNs have a reduced number of parameters to train and converge faster with fewer epochs. However, this is a quantum algorithm simulated on classical computers hence the training time for quantum circuits tend to be longer than classical models.\n",
    "\n",
    "The dataset used in this example can be found at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "This file is organized in the following order:\n",
    "0. Install and import necessary packages\n",
    "1. Load and preprocess data (The data from Kaggle is saved as 'financial.csv'.)\n",
    "2. Data encoding\n",
    "3. QNN model\n",
    "   * QNN layer\n",
    "   * QNN circuit\n",
    "   * Model building\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "\n",
    "For the open source repository, refer to https://github.com/qaintumai/quantum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Intall Packages**\n",
    "\n",
    "Ensure you have installed the packages detailed in requirements.txt before running the code below.\n",
    "\n",
    "[Pennylane](https://pennylane.ai/) is a Python based quantum machine learning library by Xanadu. An old version is necessary for this example: v0.29.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load and Preprocess Data**\n",
    "\n",
    "Data: \n",
    "\n",
    "Data points: \n",
    "\n",
    "Number of features: \n",
    "\n",
    "Label: \n",
    "\n",
    "For the purpose of this experiment, we are using only ___ data points for training and __ for testing.\n",
    "\n",
    "data source: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset:  4\n",
      "Size of X tensor: torch.Size([4, 8]) and first element of X: tensor([  0.0000, 137.0000,  40.0000,  35.0000, 168.0000,  43.1000,   2.2880,\n",
      "         33.0000])\n",
      "Size of Y tensor: torch.Size([4, 1]) and first element of Y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "#LOADING DATA\n",
    "import sys\n",
    "import os\n",
    "script_dir = os.getcwd()\n",
    "data_path = os.path.join(script_dir, '../examples/data/pima-indians-diabetes.csv')\n",
    "data_path = os.path.normpath(data_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = np.loadtxt(data_path, delimiter=',')\n",
    "\n",
    "print(\"length of dataset: \", len(dataset))\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(f\"Size of X tensor: {X.size()} and first element of X: {X[0]}\")\n",
    "print(f\"Size of Y tensor: {y.size()} and first element of Y: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Encoding**\n",
    "\n",
    "This step converts classical data into a quantum state by using the data entries as parameters of the quantum gates.\n",
    "\n",
    "The data encoding gates used are Squeezing, Rotation, Beamsplitter, Displacement Gate, and Kerr Gate. Other gates under \"CV operators\" in the Pennylane package can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, num_wires):\n",
    "        \"\"\"\n",
    "        Encodes the input data into a quantum state to be operated on using a sequence of quantum gates.\n",
    "\n",
    "        Parameters:\n",
    "        x : input data (list or array-like)\n",
    "\n",
    "        The encoding process uses the following gates in sequence:\n",
    "        - Squeezing gates: 2*self.num_wires parameters\n",
    "        - Beamsplitter gates: 2(self.num_wires-1) parameters\n",
    "        - Rotation gates: self.num_wires parameters\n",
    "        - Displacement gates: 2*self.num_wires parameters\n",
    "        - Kerr gates: self.num_wires parameters\n",
    "          Total: 8*self.num_wires - 2 parameters\n",
    "\n",
    "        rounds: the number of iterations of the sequence needed to take in all the entries of the input data\n",
    "                num_features // (8 * self.num_wires - 2)\n",
    "                We are adding (8 * self.num_wires - 3) as a pad to run one extra round for the remainding data entries.\n",
    "        \"\"\"\n",
    "        num_features = len(x)\n",
    "        \n",
    "\n",
    "        # Calculate the number of rounds needed to process all features\n",
    "        rounds = (num_features + (8 * num_wires - 3)) // (8 * num_wires - 2)\n",
    "        print(\"encoding rounds\", rounds)\n",
    "\n",
    "        for j in range(rounds):\n",
    "            start_idx = j * (8 * num_wires - 2)\n",
    "\n",
    "            # Squeezing gates\n",
    "            for i in range(num_wires):\n",
    "                # for each wire, the number of parameters are i*2\n",
    "                idx = start_idx + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Squeezing(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Beamsplitter gates\n",
    "            for i in range(num_wires - 1):\n",
    "                # start_index + Squeezing gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Beamsplitter(x[idx], x[idx + 1], wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "            # Rotation gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Rotation(x[idx], wires=i)\n",
    "\n",
    "            # Displacement gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Displacement(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Kerr gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates + Displacement gates, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Kerr(x[idx], wires=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. QNN Model**\n",
    "To build a model, we need to\n",
    "* define a layer\n",
    "* build a circuit with the defined layer\n",
    "* build a model with the defined circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 QNN Layer**\n",
    "This in a faithful implementation of classical neural networks:\n",
    "* Weight matrix: Interferometer 1 + Squeezing + Interferometer 2\n",
    "* Bias addition: Displacement gate\n",
    "* Nonlinear activation function: Kerr gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(v, num_wires):\n",
    "        \"\"\"\n",
    "        Applies the quantum neural network layer with the given parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - v (list or array): List or array of parameters for the quantum gates.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        num_params = len(v)\n",
    "\n",
    "        # Interferometer 1\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Squeezers\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Squeezing(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Interferometer 2\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Bias addition\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Displacement(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Non-linear activation function\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Kerr(v[idx], wires=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight Initializer**\n",
    "\n",
    "Randomly initialized values are used as initial parameters of the QNN circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layers, num_wires, active_sd=0.0001, passive_sd=0.1):\n",
    "    \"\"\"\n",
    "    This is a weight vector initializer.\n",
    "    Input: number of layers, number of wires\n",
    "    Output: concatenated weight vector\n",
    "    \"\"\"\n",
    "    M = (num_wires - 1) * 2 + num_wires  # Number of interferometer parameters\n",
    "\n",
    "    int1_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    print(\"size for int1\", int1_weights.size)\n",
    "    s_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #squeezers\n",
    "    print(\"size for s_weights\", int1_weights.size)\n",
    "    int2_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    print(\"size for int2\", int2_weights.size)\n",
    "    dr_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #displacement\n",
    "    print(\"size for dr_weights\", dr_weights.size)\n",
    "    k_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #Kerr\n",
    "    print(\"size for k_weights\", k_weights.size)\n",
    "\n",
    "    weights = np.concatenate(\n",
    "        [int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 QNN Circuit**\n",
    "\n",
    "For building a PA circuit as opposed to a qubit-based circuit, we have to choose \"strawberryfields.fock\" as device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires = 4\n",
    "num_basis = 2\n",
    "encoding = True\n",
    "# select a device\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_wires, cutoff_dim=num_basis)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \"\"\"\n",
    "    This is a quantum circuit composed of a data encoding circuit and a QNN circuit.\n",
    "    Input: classical data (inputs), quantum parameters (var)\n",
    "    Output: quantum state, converted to classical data after measurement\n",
    "    \"\"\"\n",
    "    global encoding\n",
    "    if (encoding):\n",
    "    # convert classical inputs into quantum states\n",
    "        encode(inputs, num_wires)\n",
    "        print(\"ENCODED inputs\")\n",
    "    # iterative quantum layers\n",
    "    encoding = False\n",
    "    print(\"length of var\", len(var))\n",
    "    print(\"shape of var\", var.shape)\n",
    "    for v in var:\n",
    "        print(\"Looking at v\", v)\n",
    "        apply(v, num_wires)\n",
    "\n",
    "    # measure the resulting state and return\n",
    "    return qml.expval(qml.X(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "def get_model(num_wires, num_layers):\n",
    "    \"\"\"\n",
    "    This is a model building function.\n",
    "    Input: number of modes, number of layers\n",
    "    Output: PyTorch model\n",
    "    \"\"\"\n",
    "    weights = init_weights(num_layers, num_wires)\n",
    "    print(\"shape of weights\", weights.shape)\n",
    "    print(\"weights length: \", len(weights))\n",
    "    print(\"weights looks like: \", weights[0][1])\n",
    "\n",
    "    shape_tup = weights.shape\n",
    "    weight_shapes = {'var': shape_tup}\n",
    "    qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
    "    model = torch.nn.Sequential(qlayer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size for int1 20\n",
      "size for s_weights 20\n",
      "size for int2 20\n",
      "size for dr_weights 8\n",
      "size for k_weights 8\n",
      "shape of weights (2, 32)\n",
      "weights length:  2\n",
      "weights looks like:  0.09846326275347056\n",
      "<generator object Module.parameters at 0x17af112a0>\n",
      "Sequential(\n",
      "  (0): <Quantum Torch Layer: func=quantum_nn>\n",
      ")\n",
      "Total number of model parameters: 64\n",
      "parameter:  Parameter containing:\n",
      "tensor([[5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "         4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "         4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "         0.7307, 5.7687, 3.4351, 4.4271, 3.3140],\n",
      "        [6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "         0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "         1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "         5.1905, 1.2950, 4.6301, 3.0443, 3.1046]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_wires, num_layers)\n",
    "print(model.parameters())\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of model parameters: {total_params}\")\n",
    "for p in model.parameters():\n",
    "    print(\"parameter: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "+++++++++++++++ Epoch 0 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 0.5\n",
      "Finished epoch 0, latest loss 0.5\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 1 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 0.5\n",
      "Finished epoch 1, latest loss 0.5\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 2 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "Looking at v tensor([5.6802, 3.3705, 0.1740, 0.1997, 0.6523, 6.0451, 2.6568, 4.5011, 4.9300,\n",
      "        4.0147, 0.3425, 2.8640, 4.3010, 5.1482, 1.0441, 2.6092, 1.9265, 0.0997,\n",
      "        4.4783, 3.0309, 5.1186, 4.1797, 4.4110, 5.6194, 3.0499, 5.9269, 5.8403,\n",
      "        0.7307, 5.7687, 3.4351, 4.4271, 3.3140], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([6.0813, 0.6393, 2.5074, 1.5122, 5.6054, 3.3124, 0.8831, 0.9281, 1.8431,\n",
      "        0.5053, 1.8957, 3.4127, 4.2681, 0.8699, 3.5787, 4.7822, 3.0957, 3.7877,\n",
      "        1.9716, 6.0924, 3.8233, 3.8633, 3.8259, 4.1648, 4.8795, 1.4933, 3.2557,\n",
      "        5.1905, 1.2950, 4.6301, 3.0443, 3.1046], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 2, latest loss 0.5\n"
     ]
    }
   ],
   "source": [
    "# TRAINING MODEL (without batching)\n",
    "loss_fn = torch.nn.L1Loss()  # binary cross-entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"+++++++++++++++ Epoch {epoch} ++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"====================================================================================\")\n",
    "\n",
    "    y_pred = model(X).reshape(-1, 1)  \n",
    "    print(f\"Size of y_pred: {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(f\"loss = {loss}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "\n",
    "# #TRAINING MODEL\n",
    "# loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# n_epochs = 1\n",
    "# batch_size = 2\n",
    " \n",
    "# for epoch in range(n_epochs):\n",
    "#     for i in range(0, len(X), batch_size):\n",
    "#         print(\"====================================================================================\")\n",
    "#         print(f\"+++++++++++++++Batch number: {i} in Epoch {epoch}++++++++++++++++++++++++++++++++++\")\n",
    "#         print(\"====================================================================================\")\n",
    "\n",
    "#         Xbatch = X[i:i+batch_size]\n",
    "#         print(f\"Size of Xbatch: {Xbatch.size()}\")\n",
    "#         y_pred = model(Xbatch).reshape(-1, 1)  \n",
    "#         print(f\"Size of y_pred: {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "#         ybatch = y[i:i+batch_size]\n",
    "#         loss = loss_fn(y_pred, ybatch)\n",
    "#         print(f\"loss = {loss}\")\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     print(f'Finished epoch {epoch}, latest loss {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "\n",
    "    print(f\"Size of y_pred (evaluation): {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ISOLATED TESTING**\n",
    "\n",
    "Beware and steer clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input data once outside the training loop\n",
    "encoded_data = None\n",
    "encoding = True\n",
    "def encode_data_once(x, num_wires):\n",
    "    \"\"\" Encodes the data only once and stores it. \"\"\"\n",
    "    global encoded_data\n",
    "    if encoded_data is None:\n",
    "        encode(x, num_wires)\n",
    "        encoded_data = True  # Indicates that encoding has been done\n",
    "        print(f\"ENCODED inputs: {x}\")\n",
    "    else:\n",
    "        print(\"Using cached encoded inputs.\")\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \"\"\" Quantum Neural Network with a caching mechanism for encoded inputs. \"\"\"\n",
    "    global encoding\n",
    "    if encoding:\n",
    "        encode_data_once(inputs, num_wires)  # Encode only once\n",
    "        encoding = False\n",
    "    print(\"length of var\", len(var))\n",
    "    print(\"shape of var\", var.shape)\n",
    "    for v in var:\n",
    "        print(\"--- Applying Layer ---\")\n",
    "        print(f\"Parameters for this layer: {v}\")\n",
    "        apply(v, num_wires)\n",
    "    return qml.expval(qml.X(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size for int1 20\n",
      "size for s_weights 20\n",
      "size for int2 20\n",
      "size for dr_weights 8\n",
      "size for k_weights 8\n",
      "size for int1 20\n",
      "size for s_weights 20\n",
      "size for int2 20\n",
      "size for dr_weights 8\n",
      "size for k_weights 8\n",
      "shape of weights (2, 32)\n",
      "weights length:  2\n",
      "weights looks like:  0.03538308315641023\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 0 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "encoding rounds 1\n",
      "ENCODED inputs: tensor([  0.0000, 137.0000,  40.0000,  35.0000, 168.0000,  43.1000,   2.2880,\n",
      "         33.0000])\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([1.0603, 2.8039, 2.7515, 5.1245, 1.2353, 1.3466, 3.7217, 1.2563, 2.6239,\n",
      "        4.6288, 2.7507, 2.9677, 0.8495, 0.1244, 2.0035, 5.2682, 5.6754, 3.9982,\n",
      "        1.4356, 5.8710, 3.0230, 2.0916, 1.0574, 2.2542, 1.5702, 5.1163, 2.9667,\n",
      "        3.1096, 1.9404, 4.3269, 1.5989, 0.1363], grad_fn=<UnbindBackward0>)\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([0.2229, 1.3538, 3.8192, 2.4560, 0.2555, 4.6133, 3.0476, 0.4759, 1.4686,\n",
      "        2.9170, 2.1304, 5.0237, 2.4795, 2.1703, 4.7288, 5.8955, 2.5057, 2.0602,\n",
      "        1.6788, 1.5363, 2.3973, 5.5790, 1.6307, 0.1897, 2.7554, 4.8550, 4.4392,\n",
      "        0.1331, 2.3321, 3.1824, 5.2516, 2.7064], grad_fn=<UnbindBackward0>)\n",
      "Output from the quantum circuit with test input: -0.0\n",
      "Loss = 1.0\n",
      "Finished epoch 0, latest loss 1.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 1 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([1.0603, 2.8039, 2.7515, 5.1245, 1.2353, 1.3466, 3.7217, 1.2563, 2.6239,\n",
      "        4.6288, 2.7507, 2.9677, 0.8495, 0.1244, 2.0035, 5.2682, 5.6754, 3.9982,\n",
      "        1.4356, 5.8710, 3.0230, 2.0916, 1.0574, 2.2542, 1.5702, 5.1163, 2.9667,\n",
      "        3.1096, 1.9404, 4.3269, 1.5989, 0.1363], grad_fn=<UnbindBackward0>)\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([0.2229, 1.3538, 3.8192, 2.4560, 0.2555, 4.6133, 3.0476, 0.4759, 1.4686,\n",
      "        2.9170, 2.1304, 5.0237, 2.4795, 2.1703, 4.7288, 5.8955, 2.5057, 2.0602,\n",
      "        1.6788, 1.5363, 2.3973, 5.5790, 1.6307, 0.1897, 2.7554, 4.8550, 4.4392,\n",
      "        0.1331, 2.3321, 3.1824, 5.2516, 2.7064], grad_fn=<UnbindBackward0>)\n",
      "Output from the quantum circuit with test input: -9.80908925027372e-45\n",
      "Loss = 1.0\n",
      "Finished epoch 1, latest loss 1.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 2 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([1.0603, 2.8039, 2.7515, 5.1245, 1.2353, 1.3466, 3.7217, 1.2563, 2.6239,\n",
      "        4.6288, 2.7507, 2.9677, 0.8495, 0.1244, 2.0035, 5.2682, 5.6754, 3.9982,\n",
      "        1.4356, 5.8710, 3.0230, 2.0916, 1.0574, 2.2542, 1.5702, 5.1163, 2.9667,\n",
      "        3.1096, 1.9404, 4.3269, 1.5989, 0.1363], grad_fn=<UnbindBackward0>)\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([0.2229, 1.3538, 3.8192, 2.4560, 0.2555, 4.6133, 3.0476, 0.4759, 1.4686,\n",
      "        2.9170, 2.1304, 5.0237, 2.4795, 2.1703, 4.7288, 5.8955, 2.5057, 2.0602,\n",
      "        1.6788, 1.5363, 2.3973, 5.5790, 1.6307, 0.1897, 2.7554, 4.8550, 4.4392,\n",
      "        0.1331, 2.3321, 3.1824, 5.2516, 2.7064], grad_fn=<UnbindBackward0>)\n",
      "Output from the quantum circuit with test input: -9.80908925027372e-45\n",
      "Loss = 1.0\n",
      "Finished epoch 2, latest loss 1.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 3 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([1.0603, 2.8039, 2.7515, 5.1245, 1.2353, 1.3466, 3.7217, 1.2563, 2.6239,\n",
      "        4.6288, 2.7507, 2.9677, 0.8495, 0.1244, 2.0035, 5.2682, 5.6754, 3.9982,\n",
      "        1.4356, 5.8710, 3.0230, 2.0916, 1.0574, 2.2542, 1.5702, 5.1163, 2.9667,\n",
      "        3.1096, 1.9404, 4.3269, 1.5989, 0.1363], grad_fn=<UnbindBackward0>)\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([0.2229, 1.3538, 3.8192, 2.4560, 0.2555, 4.6133, 3.0476, 0.4759, 1.4686,\n",
      "        2.9170, 2.1304, 5.0237, 2.4795, 2.1703, 4.7288, 5.8955, 2.5057, 2.0602,\n",
      "        1.6788, 1.5363, 2.3973, 5.5790, 1.6307, 0.1897, 2.7554, 4.8550, 4.4392,\n",
      "        0.1331, 2.3321, 3.1824, 5.2516, 2.7064], grad_fn=<UnbindBackward0>)\n",
      "Output from the quantum circuit with test input: -9.80908925027372e-45\n",
      "Loss = 1.0\n",
      "Finished epoch 3, latest loss 1.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 4 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var torch.Size([2, 32])\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([1.0603, 2.8039, 2.7515, 5.1245, 1.2353, 1.3466, 3.7217, 1.2563, 2.6239,\n",
      "        4.6288, 2.7507, 2.9677, 0.8495, 0.1244, 2.0035, 5.2682, 5.6754, 3.9982,\n",
      "        1.4356, 5.8710, 3.0230, 2.0916, 1.0574, 2.2542, 1.5702, 5.1163, 2.9667,\n",
      "        3.1096, 1.9404, 4.3269, 1.5989, 0.1363], grad_fn=<UnbindBackward0>)\n",
      "--- Applying Layer ---\n",
      "Parameters for this layer: tensor([0.2229, 1.3538, 3.8192, 2.4560, 0.2555, 4.6133, 3.0476, 0.4759, 1.4686,\n",
      "        2.9170, 2.1304, 5.0237, 2.4795, 2.1703, 4.7288, 5.8955, 2.5057, 2.0602,\n",
      "        1.6788, 1.5363, 2.3973, 5.5790, 1.6307, 0.1897, 2.7554, 4.8550, 4.4392,\n",
      "        0.1331, 2.3321, 3.1824, 5.2516, 2.7064], grad_fn=<UnbindBackward0>)\n",
      "Output from the quantum circuit with test input: -9.80908925027372e-45\n",
      "Loss = 1.0\n",
      "Finished epoch 4, latest loss 1.0\n"
     ]
    }
   ],
   "source": [
    "# Simple test input\n",
    "test_input = torch.tensor([0, 137, 40, 35, 168, 43.1, 2.288, 33], dtype=torch.float32)\n",
    "\n",
    "# Initialize weights with known values or use random values for testing\n",
    "test_weights = init_weights(num_layers, num_wires, active_sd=0.01, passive_sd=0.1)\n",
    "test_weights = torch.tensor(test_weights, dtype=torch.float32)\n",
    "\n",
    "# Define a simple model with the quantum layer\n",
    "model = get_model(num_wires, num_layers)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "loss_fn = nn.L1Loss()  # Mean Absolute Error Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# Target output for the test case (arbitrary for testing purposes)\n",
    "y_test = torch.tensor([1.0], dtype=torch.float32)\n",
    "\n",
    "# Run the training loop for 5 iterations\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"+++++++++++++++ Epoch {epoch} ++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"====================================================================================\")\n",
    "\n",
    "    # Forward pass: predict using the model\n",
    "    y_pred = model(test_input).reshape(-1, 1)\n",
    "    print(f\"Output from the quantum circuit with test input: {y_pred.item()}\")\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred, y_test)\n",
    "    print(f\"Loss = {loss.item()}\")\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eed3d6a5ebd92ef48ec685a6188b4208468e30da06e40b2114167f15b521e1ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
