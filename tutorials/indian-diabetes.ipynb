{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**qAIntum.ai**\n",
    "\n",
    "# **Quantum Neural Network (QNN) Classifier**\n",
    "\n",
    "This note is an example of using Photonic Analog (PA) QNN for binary classification. This is an application of the original work [\"Continuous Variable Quantum Neural Networks\"](https://arxiv.org/abs/1806.06871).\n",
    "\n",
    "Compared to Classical Neural Networks, PA QNNs have a reduced number of parameters to train and converge faster with fewer epochs. However, this is a quantum algorithm simulated on classical computers hence the training time for quantum circuits tend to be longer than classical models.\n",
    "\n",
    "The dataset used in this example can be found at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "This file is organized in the following order:\n",
    "0. Install and import necessary packages\n",
    "1. Load and preprocess data (The data from Kaggle is saved as 'financial.csv'.)\n",
    "2. Data encoding\n",
    "3. QNN model\n",
    "   * QNN layer\n",
    "   * QNN circuit\n",
    "   * Model building\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "\n",
    "For the open source repository, refer to https://github.com/qaintumai/quantum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Intall Packages**\n",
    "\n",
    "Ensure you have installed the packages detailed in requirements.txt before running the code below.\n",
    "\n",
    "[Pennylane](https://pennylane.ai/) is a Python based quantum machine learning library by Xanadu. An old version is necessary for this example: v0.29.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load and Preprocess Data**\n",
    "\n",
    "Data: \n",
    "\n",
    "Data points: \n",
    "\n",
    "Number of features: \n",
    "\n",
    "Label: \n",
    "\n",
    "For the purpose of this experiment, we are using only ___ data points for training and __ for testing.\n",
    "\n",
    "data source: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset:  4\n",
      "Size of X tensor: torch.Size([4, 8]) and first element of X: tensor([  0.0000, 137.0000,  40.0000,  35.0000, 168.0000,  43.1000,   2.2880,\n",
      "         33.0000])\n",
      "Size of Y tensor: torch.Size([4, 1]) and first element of Y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "#LOADING DATA\n",
    "import sys\n",
    "import os\n",
    "script_dir = os.getcwd()\n",
    "data_path = os.path.join(script_dir, '../examples/data/pima-indians-diabetes.csv')\n",
    "data_path = os.path.normpath(data_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = np.loadtxt(data_path, delimiter=',')\n",
    "\n",
    "print(\"length of dataset: \", len(dataset))\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(f\"Size of X tensor: {X.size()} and first element of X: {X[0]}\")\n",
    "print(f\"Size of Y tensor: {y.size()} and first element of Y: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Encoding**\n",
    "\n",
    "This step converts classical data into a quantum state by using the data entries as parameters of the quantum gates.\n",
    "\n",
    "The data encoding gates used are Squeezing, Rotation, Beamsplitter, Displacement Gate, and Kerr Gate. Other gates under \"CV operators\" in the Pennylane package can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, num_wires):\n",
    "        \"\"\"\n",
    "        Encodes the input data into a quantum state to be operated on using a sequence of quantum gates.\n",
    "\n",
    "        Parameters:\n",
    "        x : input data (list or array-like)\n",
    "\n",
    "        The encoding process uses the following gates in sequence:\n",
    "        - Squeezing gates: 2*self.num_wires parameters\n",
    "        - Beamsplitter gates: 2(self.num_wires-1) parameters\n",
    "        - Rotation gates: self.num_wires parameters\n",
    "        - Displacement gates: 2*self.num_wires parameters\n",
    "        - Kerr gates: self.num_wires parameters\n",
    "          Total: 8*self.num_wires - 2 parameters\n",
    "\n",
    "        rounds: the number of iterations of the sequence needed to take in all the entries of the input data\n",
    "                num_features // (8 * self.num_wires - 2)\n",
    "                We are adding (8 * self.num_wires - 3) as a pad to run one extra round for the remainding data entries.\n",
    "        \"\"\"\n",
    "        num_features = len(x)\n",
    "        \n",
    "\n",
    "        # Calculate the number of rounds needed to process all features\n",
    "        rounds = (num_features + (8 * num_wires - 3)) // (8 * num_wires - 2)\n",
    "\n",
    "        for j in range(rounds):\n",
    "            start_idx = j * (8 * num_wires - 2)\n",
    "\n",
    "            # Squeezing gates\n",
    "            for i in range(num_wires):\n",
    "                # for each wire, the number of parameters are i*2\n",
    "                idx = start_idx + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Squeezing(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Beamsplitter gates\n",
    "            for i in range(num_wires - 1):\n",
    "                # start_index + Squeezing gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Beamsplitter(x[idx], x[idx + 1], wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "            # Rotation gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Rotation(x[idx], wires=i)\n",
    "\n",
    "            # Displacement gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Displacement(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Kerr gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates + Displacement gates, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Kerr(x[idx], wires=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. QNN Model**\n",
    "To build a model, we need to\n",
    "* define a layer\n",
    "* build a circuit with the defined layer\n",
    "* build a model with the defined circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 QNN Layer**\n",
    "This in a faithful implementation of classical neural networks:\n",
    "* Weight matrix: Interferometer 1 + Squeezing + Interferometer 2\n",
    "* Bias addition: Displacement gate\n",
    "* Nonlinear activation function: Kerr gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(v, num_wires):\n",
    "        \"\"\"\n",
    "        Applies the quantum neural network layer with the given parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - v (list or array): List or array of parameters for the quantum gates.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        num_params = len(v)\n",
    "\n",
    "        # Interferometer 1\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Squeezers\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Squeezing(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Interferometer 2\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Bias addition\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Displacement(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Non-linear activation function\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Kerr(v[idx], wires=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight Initializer**\n",
    "\n",
    "Randomly initialized values are used as initial parameters of the QNN circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layers, num_wires, active_sd=0.0001, passive_sd=0.1):\n",
    "    \"\"\"\n",
    "    This is a weight vector initializer.\n",
    "    Input: number of layers, number of wires\n",
    "    Output: concatenated weight vector\n",
    "    \"\"\"\n",
    "    M = (num_wires - 1) * 2 + num_wires  # Number of interferometer parameters\n",
    "\n",
    "    int1_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    print(\"size for int1\", int1_weights.size)\n",
    "    s_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #squeezers\n",
    "    print(\"size for s_weights\", int1_weights.size)\n",
    "    int2_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    print(\"size for int2\", int2_weights.size)\n",
    "    dr_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #displacement\n",
    "    print(\"size for dr_weights\", dr_weights.size)\n",
    "    k_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #Kerr\n",
    "    print(\"size for k_weights\", k_weights.size)\n",
    "\n",
    "    weights = np.concatenate(\n",
    "        [int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 QNN Circuit**\n",
    "\n",
    "For building a PA circuit as opposed to a qubit-based circuit, we have to choose \"strawberryfields.fock\" as device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires = 6\n",
    "num_basis = 2\n",
    "encoding = True\n",
    "# select a device\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_wires, cutoff_dim=num_basis)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \"\"\"\n",
    "    This is a quantum circuit composed of a data encoding circuit and a QNN circuit.\n",
    "    Input: classical data (inputs), quantum parameters (var)\n",
    "    Output: quantum state, converted to classical data after measurement\n",
    "    \"\"\"\n",
    "    global encoding\n",
    "    if (encoding):\n",
    "    # convert classical inputs into quantum states\n",
    "        encode(inputs, num_wires)\n",
    "        print(\"ENCODED inputs\")\n",
    "    # iterative quantum layers\n",
    "    encoding = False\n",
    "    print(\"length of var\", len(var))\n",
    "    print(\"shape of var\", var)\n",
    "    for v in var:\n",
    "        print(\"Looking at v\", v)\n",
    "        apply(v, num_wires)\n",
    "\n",
    "    # measure the resulting state and return\n",
    "    return qml.expval(qml.X(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "def get_model(num_wires, num_layers):\n",
    "    \"\"\"\n",
    "    This is a model building function.\n",
    "    Input: number of modes, number of layers\n",
    "    Output: PyTorch model\n",
    "    \"\"\"\n",
    "    weights = init_weights(num_layers, num_wires)\n",
    "    print(\"shape of weights\", weights.shape)\n",
    "    print(\"weights length: \", len(weights))\n",
    "    print(\"weights looks like: \", weights)\n",
    "\n",
    "    shape_tup = weights.shape\n",
    "    weight_shapes = {'var': shape_tup}\n",
    "    qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
    "    model = torch.nn.Sequential(qlayer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size for int1 32\n",
      "size for s_weights 32\n",
      "size for int2 32\n",
      "size for dr_weights 12\n",
      "size for k_weights 12\n",
      "shape of weights (2, 50)\n",
      "weights length:  2\n",
      "weights looks like:  [[-1.16851421e-01  1.67812155e-01  2.95327965e-02  6.81457164e-02\n",
      "   1.68259350e-03  3.87290226e-02 -2.89300569e-03 -3.64511243e-02\n",
      "   2.76288163e-02 -1.03527997e-01  7.02983371e-03 -3.55590160e-02\n",
      "   2.22785986e-02  2.06311991e-01  1.69177628e-01  9.87147181e-02\n",
      "  -9.60224615e-05  1.63309366e-04 -8.38320013e-05 -1.31867330e-04\n",
      "  -2.42863874e-05  3.94700503e-05 -1.06718602e-01 -1.50193733e-01\n",
      "   1.72952266e-01 -1.72719465e-01 -8.65238461e-03 -1.22612943e-02\n",
      "   6.03665579e-02 -1.73792384e-01 -3.02997738e-02 -1.47928726e-01\n",
      "  -1.89287698e-02  8.10293675e-02  2.90769800e-02 -5.21092390e-02\n",
      "  -9.01494115e-02 -6.03762048e-02 -9.13009316e-05  2.54509575e-05\n",
      "   9.14632862e-05 -1.24810635e-05  1.64402016e-04 -1.59590927e-04\n",
      "  -9.60401403e-05 -4.94084758e-05  2.16390917e-04  6.88148841e-05\n",
      "  -2.66228336e-05  1.05975849e-05]\n",
      " [ 4.71538389e-03  1.25137287e-01  1.56216177e-01  4.73594931e-02\n",
      "  -7.52971170e-02  1.33594927e-01  3.15191311e-02  9.03447567e-02\n",
      "  -3.88763770e-03 -5.02350034e-02 -1.18075818e-01 -2.32663413e-02\n",
      "  -9.12871714e-02 -2.61479985e-02 -7.81774284e-02  5.74933064e-02\n",
      "   1.08903384e-05 -4.23505206e-05 -5.58719127e-06  1.49775509e-04\n",
      "  -8.41618828e-05 -6.87138956e-05 -8.62528533e-02 -1.11556098e-01\n",
      "  -1.95460499e-01  1.08193351e-01  7.72093230e-02  1.00713195e-01\n",
      "  -1.87614750e-01 -5.57082362e-02  4.10041975e-02 -6.50576497e-02\n",
      "   1.17269926e-01 -6.08610575e-03 -4.84955982e-02  4.64066471e-02\n",
      "   7.83749348e-02  5.20209695e-02 -1.90439888e-05 -1.51581253e-04\n",
      "   1.13595646e-04 -6.16294420e-05 -5.27926431e-05 -1.06961861e-04\n",
      "   7.61335253e-05 -8.76448144e-05  8.79899484e-05 -1.11272120e-04\n",
      "  -1.53795138e-04 -7.43862196e-05]]\n",
      "<generator object Module.parameters at 0x13cc8d9a0>\n",
      "Sequential(\n",
      "  (0): <Quantum Torch Layer: func=quantum_nn>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_wires, num_layers)\n",
    "print(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "+++++++++++++++ Epoch 0 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "ENCODED inputs\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 50.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 50.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 1 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 50.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1, latest loss 50.0\n",
      "====================================================================================\n",
      "+++++++++++++++ Epoch 2 ++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "length of var 2\n",
      "shape of var Parameter containing:\n",
      "tensor([[0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "         1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "         5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "         3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "         3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "         1.9587, 1.9196, 2.9995, 4.4606, 1.7446],\n",
      "        [5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "         4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "         3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "         6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "         5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "         2.6876, 0.3532, 2.9390, 5.6822, 3.5001]], requires_grad=True)\n",
      "Looking at v tensor([0.6188, 3.4725, 1.1830, 5.6985, 3.7470, 0.2290, 5.9576, 3.2500, 0.7172,\n",
      "        1.8674, 3.2363, 1.0611, 5.2961, 3.3458, 3.7720, 3.7935, 4.7406, 1.7252,\n",
      "        5.3179, 5.9701, 4.4455, 0.0850, 3.5281, 1.7167, 6.0850, 5.1010, 1.5335,\n",
      "        3.2138, 2.6934, 2.6039, 3.3348, 1.7066, 0.6206, 3.6260, 2.9784, 3.7458,\n",
      "        3.9525, 1.7914, 1.6596, 3.5346, 1.4543, 5.0542, 3.3881, 1.2243, 4.2954,\n",
      "        1.9587, 1.9196, 2.9995, 4.4606, 1.7446], grad_fn=<UnbindBackward0>)\n",
      "Looking at v tensor([5.5083, 4.1764, 0.4911, 1.0041, 1.9779, 0.0150, 2.4890, 2.0797, 5.9024,\n",
      "        4.6920, 3.0090, 1.9735, 0.0604, 5.2121, 5.4823, 4.0740, 0.0171, 0.1961,\n",
      "        3.5601, 1.8875, 0.8000, 5.6284, 3.9486, 1.1805, 5.7964, 1.2599, 3.9713,\n",
      "        6.2120, 4.2446, 3.5406, 4.2044, 2.7415, 2.7199, 4.1484, 1.1152, 5.6122,\n",
      "        5.2882, 4.2306, 2.8547, 0.7739, 2.9047, 6.1464, 3.7250, 4.4305, 5.5255,\n",
      "        2.6876, 0.3532, 2.9390, 5.6822, 3.5001], grad_fn=<UnbindBackward0>)\n",
      "Size of y_pred: torch.Size([4, 1]), Values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ViewBackward0>)\n",
      "loss = 50.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 2, latest loss 50.0\n"
     ]
    }
   ],
   "source": [
    "# TRAINING MODEL (without batching)\n",
    "loss_fn = nn.BCELoss()  # binary cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"+++++++++++++++ Epoch {epoch} ++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"====================================================================================\")\n",
    "\n",
    "    y_pred = model(X).reshape(-1, 1)  \n",
    "    print(f\"Size of y_pred: {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(f\"loss = {loss}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "\n",
    "# #TRAINING MODEL\n",
    "# loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# n_epochs = 1\n",
    "# batch_size = 2\n",
    " \n",
    "# for epoch in range(n_epochs):\n",
    "#     for i in range(0, len(X), batch_size):\n",
    "#         print(\"====================================================================================\")\n",
    "#         print(f\"+++++++++++++++Batch number: {i} in Epoch {epoch}++++++++++++++++++++++++++++++++++\")\n",
    "#         print(\"====================================================================================\")\n",
    "\n",
    "#         Xbatch = X[i:i+batch_size]\n",
    "#         print(f\"Size of Xbatch: {Xbatch.size()}\")\n",
    "#         y_pred = model(Xbatch).reshape(-1, 1)  \n",
    "#         print(f\"Size of y_pred: {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "#         ybatch = y[i:i+batch_size]\n",
    "#         loss = loss_fn(y_pred, ybatch)\n",
    "#         print(f\"loss = {loss}\")\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     print(f'Finished epoch {epoch}, latest loss {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "\n",
    "    print(f\"Size of y_pred (evaluation): {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eed3d6a5ebd92ef48ec685a6188b4208468e30da06e40b2114167f15b521e1ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
