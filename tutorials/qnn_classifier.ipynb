{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**qAIntum.ai**\n",
    "\n",
    "# **Quantum Neural Network (QNN) Classifier**\n",
    "\n",
    "This note is an example of using Photonic Analog (PA) QNN for binary classification. This is an application of the original work [\"Continuous Variable Quantum Neural Networks\"](https://arxiv.org/abs/1806.06871).\n",
    "\n",
    "Compared to Classical Neural Networks, PA QNNs have a reduced number of parameters to train and converge faster with fewer epochs. However, this is a quantum algorithm simulated on classical computers hence the training time for quantum circuits tend to be longer than classical models.\n",
    "\n",
    "The dataset used in this example can be found at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "This file is organized in the following order:\n",
    "0. Install and import necessary packages\n",
    "1. Load and preprocess data (The data from Kaggle is saved as 'financial.csv'.)\n",
    "2. Data encoding\n",
    "3. QNN model\n",
    "   * QNN layer\n",
    "   * QNN circuit\n",
    "   * Model building\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "\n",
    "For the open source repository, refer to https://github.com/qaintumai/quantum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Intall Packages**\n",
    "\n",
    "Ensure you have installed the packages detailed in requirements.txt before running the code below.\n",
    "\n",
    "[Pennylane](https://pennylane.ai/) is a Python based quantum machine learning library by Xanadu. An old version is necessary for this example: v0.29.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load and Preprocess Data**\n",
    "\n",
    "Data: \n",
    "\n",
    "Data points: \n",
    "\n",
    "Number of features: \n",
    "\n",
    "Label: \n",
    "\n",
    "For the purpose of this experiment, we are using only ___ data points for training and __ for testing.\n",
    "\n",
    "data source: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset:  768\n",
      "Size of X tensor: torch.Size([768, 8]) and first element of X: tensor([  6.0000, 148.0000,  72.0000,  35.0000,   0.0000,  33.6000,   0.6270,\n",
      "         50.0000])\n",
      "Size of Y tensor: torch.Size([768, 1]) and first element of Y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "#LOADING DATA\n",
    "import sys\n",
    "import os\n",
    "script_dir = os.getcwd()\n",
    "data_path = os.path.join(script_dir, '../examples/data/pima-indians-diabetes.csv')\n",
    "data_path = os.path.normpath(data_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = np.loadtxt(data_path, delimiter=',')\n",
    "\n",
    "print(\"length of dataset: \", len(dataset))\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(f\"Size of X tensor: {X.size()} and first element of X: {X[0]}\")\n",
    "print(f\"Size of Y tensor: {y.size()} and first element of Y: {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Encoding**\n",
    "\n",
    "This step converts classical data into a quantum state by using the data entries as parameters of the quantum gates.\n",
    "\n",
    "The data encoding gates used are Squeezing, Rotation, Beamsplitter, Displacement Gate, and Kerr Gate. Other gates under \"CV operators\" in the Pennylane package can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, num_wires):\n",
    "        \"\"\"\n",
    "        Encodes the input data into a quantum state to be operated on using a sequence of quantum gates.\n",
    "\n",
    "        Parameters:\n",
    "        x : input data (list or array-like)\n",
    "\n",
    "        The encoding process uses the following gates in sequence:\n",
    "        - Squeezing gates: 2*self.num_wires parameters\n",
    "        - Beamsplitter gates: 2(self.num_wires-1) parameters\n",
    "        - Rotation gates: self.num_wires parameters\n",
    "        - Displacement gates: 2*self.num_wires parameters\n",
    "        - Kerr gates: self.num_wires parameters\n",
    "          Total: 8*self.num_wires - 2 parameters\n",
    "\n",
    "        rounds: the number of iterations of the sequence needed to take in all the entries of the input data\n",
    "                num_features // (8 * self.num_wires - 2)\n",
    "                We are adding (8 * self.num_wires - 3) as a pad to run one extra round for the remainding data entries.\n",
    "        \"\"\"\n",
    "        num_features = len(x)\n",
    "        \n",
    "\n",
    "        # Calculate the number of rounds needed to process all features\n",
    "        rounds = (num_features + (8 * num_wires - 3)) // (8 * num_wires - 2)\n",
    "\n",
    "        for j in range(rounds):\n",
    "            start_idx = j * (8 * num_wires - 2)\n",
    "\n",
    "            # Squeezing gates\n",
    "            for i in range(num_wires):\n",
    "                # for each wire, the number of parameters are i*2\n",
    "                idx = start_idx + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Squeezing(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Beamsplitter gates\n",
    "            for i in range(num_wires - 1):\n",
    "                # start_index + Squeezing gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Beamsplitter(x[idx], x[idx + 1], wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "            # Rotation gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Rotation(x[idx], wires=i)\n",
    "\n",
    "            # Displacement gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates, and then i*2 parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + i * 2\n",
    "                if idx + 1 < num_features:\n",
    "                    qml.Displacement(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "            # Kerr gates\n",
    "            for i in range(num_wires):\n",
    "                # start_index + Squeezing gates + Beamsplitters + Rotation gates + Displacement gates, and then i parameters for each gate\n",
    "                idx = start_idx + num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + i\n",
    "                if idx < num_features:\n",
    "                    qml.Kerr(x[idx], wires=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. QNN Model**\n",
    "To build a model, we need to\n",
    "* define a layer\n",
    "* build a circuit with the defined layer\n",
    "* build a model with the defined circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 QNN Layer**\n",
    "This in a faithful implementation of classical neural networks:\n",
    "* Weight matrix: Interferometer 1 + Squeezing + Interferometer 2\n",
    "* Bias addition: Displacement gate\n",
    "* Nonlinear activation function: Kerr gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(v, num_wires):\n",
    "        \"\"\"\n",
    "        Applies the quantum neural network layer with the given parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - v (list or array): List or array of parameters for the quantum gates.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        num_params = len(v)\n",
    "\n",
    "        # Interferometer 1\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Squeezers\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Squeezing(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Interferometer 2\n",
    "        for i in range(num_wires - 1):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + i * 2\n",
    "            if idx + 1 < num_params:\n",
    "                theta = v[idx]\n",
    "                phi = v[idx + 1]\n",
    "                qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + i\n",
    "            if idx < num_params:\n",
    "                qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "        # Bias addition\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Displacement(v[idx], 0.0, wires=i)\n",
    "\n",
    "        # Non-linear activation function\n",
    "        for i in range(num_wires):\n",
    "            idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + num_wires + i\n",
    "            if idx < num_params:\n",
    "                qml.Kerr(v[idx], wires=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight Initializer**\n",
    "\n",
    "Randomly initialized values are used as initial parameters of the QNN circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layers, num_wires, active_sd=0.0001, passive_sd=0.1):\n",
    "    \"\"\"\n",
    "    This is a weight vector initializer.\n",
    "    Input: number of layers, number of wires\n",
    "    Output: concatenated weight vector\n",
    "    \"\"\"\n",
    "    M = (num_wires - 1) * 2 + num_wires  # Number of interferometer parameters\n",
    "\n",
    "    int1_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    s_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #squeezers\n",
    "    int2_weights = np.random.normal(size=[layers, M], scale=passive_sd) #beamsplitters and rotations\n",
    "    dr_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #displacement\n",
    "    k_weights = np.random.normal(size=[layers, num_wires], scale=active_sd) #Kerr\n",
    "\n",
    "    weights = np.concatenate(\n",
    "        [int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 QNN Circuit**\n",
    "\n",
    "For building a PA circuit as opposed to a qubit-based circuit, we have to choose \"strawberryfields.fock\" as device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires = 8\n",
    "num_basis = 2\n",
    "\n",
    "# select a device\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_wires, cutoff_dim=num_basis)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \"\"\"\n",
    "    This is a quantum circuit composed of a data encoding circuit and a QNN circuit.\n",
    "    Input: classical data (inputs), quantum parameters (var)\n",
    "    Output: quantum state, converted to classical data after measurement\n",
    "    \"\"\"\n",
    "    # convert classical inputs into quantum states\n",
    "    encode(inputs, num_wires)\n",
    "    print(\"Encoded data\")\n",
    "\n",
    "    # iterative quantum layers\n",
    "    for v in var:\n",
    "        apply(v, num_wires)\n",
    "\n",
    "    # measure the resulting state and return\n",
    "    return qml.expval(qml.X(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "def get_model(num_wires, num_layers):\n",
    "    \"\"\"\n",
    "    This is a model building function.\n",
    "    Input: number of modes, number of layers\n",
    "    Output: PyTorch model\n",
    "    \"\"\"\n",
    "    weights = init_weights(num_layers, num_wires)\n",
    "    shape_tup = weights.shape\n",
    "    weight_shapes = {'var': shape_tup}\n",
    "    qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
    "    model = torch.nn.Sequential(qlayer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x12a5d3760>\n",
      "Sequential(\n",
      "  (0): <Quantum Torch Layer: func=quantum_nn>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_wires, num_layers)\n",
    "print(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "+++++++++++++++Batch number: 0 in Epoch 0++++++++++++++++++++++++++++++++++\n",
      "====================================================================================\n",
      "Size of Xbatch: torch.Size([2, 8])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m Xbatch \u001b[38;5;241m=\u001b[39m X[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of Xbatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXbatch\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of y_pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m ybatch \u001b[38;5;241m=\u001b[39m y[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:309\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates a forward pass through the QNode based upon input data and the initialized\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39mweights.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m    tensor: output data\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39m# If the input size is not 1-dimensional, unstack the input along its first dimension,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     \u001b[39m# recursively call the forward pass on each of the yielded tensors, and then stack the\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     \u001b[39m# outputs back into the correct shape\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     reconstructor \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m torch\u001b[39m.\u001b[39munbind(inputs)]\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[1;32m    312\u001b[0m \u001b[39m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:309\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates a forward pass through the QNode based upon input data and the initialized\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39mweights.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m    tensor: output data\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39m# If the input size is not 1-dimensional, unstack the input along its first dimension,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     \u001b[39m# recursively call the forward pass on each of the yielded tensors, and then stack the\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     \u001b[39m# outputs back into the correct shape\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     reconstructor \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m torch\u001b[39m.\u001b[39munbind(inputs)]\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[1;32m    312\u001b[0m \u001b[39m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:313\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[1;32m    312\u001b[0m \u001b[39m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_qnode(inputs)\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:328\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    324\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    325\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_arg: x},\n\u001b[1;32m    326\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{arg: weight\u001b[39m.\u001b[39mto(x) \u001b[39mfor\u001b[39;00m arg, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnode_weights\u001b[39m.\u001b[39mitems()},\n\u001b[1;32m    327\u001b[0m }\n\u001b[0;32m--> 328\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnode.py:842\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         set_shots(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_device, override_shots)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_gradient_fn)()\n\u001b[1;32m    841\u001b[0m \u001b[39m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(args, kwargs)\n\u001b[1;32m    844\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    845\u001b[0m using_custom_cache \u001b[39m=\u001b[39m (\n\u001b[1;32m    846\u001b[0m     \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__getitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    847\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__setitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    848\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__delitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    849\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/qnode.py:751\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m old_interface \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    749\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterface \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mget_interface(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m--> 751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape \u001b[39m=\u001b[39m make_qscript(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39m_qfunc_output\n\u001b[1;32m    754\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39mget_parameters(trainable_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/QuAIntum/quantum/venv/lib/python3.10/site-packages/pennylane/tape/qscript.py:1371\u001b[0m, in \u001b[0;36mmake_qscript.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1370\u001b[0m     \u001b[39mwith\u001b[39;00m AnnotatedQueue() \u001b[39mas\u001b[39;00m q:\n\u001b[0;32m-> 1371\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1373\u001b[0m     qscript \u001b[39m=\u001b[39m QuantumScript\u001b[39m.\u001b[39mfrom_queue(q)\n\u001b[1;32m   1374\u001b[0m     qscript\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mquantum_nn\u001b[0;34m(inputs, var)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mThis is a quantum circuit composed of a data encoding circuit and a QNN circuit.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mInput: classical data (inputs), quantum parameters (var)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mOutput: quantum state, converted to classical data after measurement\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# convert classical inputs into quantum states\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# iterative quantum layers\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate the number of rounds needed to process all features\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m rounds \u001b[38;5;241m=\u001b[39m (num_features \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mnum_wires \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_wires \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rounds):\n\u001b[1;32m     26\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_wires \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#TRAINING MODEL\n",
    "loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 1\n",
    "batch_size = 2\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        print(\"====================================================================================\")\n",
    "        print(f\"+++++++++++++++Batch number: {i} in Epoch {epoch}++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"====================================================================================\")\n",
    "\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        print(f\"Size of Xbatch: {Xbatch.size()}\")\n",
    "        y_pred = model(Xbatch).reshape(-1, 1)  \n",
    "        print(f\"Size of y_pred: {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        print(f\"loss = {loss}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "\n",
    "    print(f\"Size of y_pred (evaluation): {y_pred.size()}, Values: {y_pred}\")\n",
    "\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eed3d6a5ebd92ef48ec685a6188b4208468e30da06e40b2114167f15b521e1ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
