{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqM5CnnKBbrM"
   },
   "source": [
    "**qAIntum.ai**\n",
    "\n",
    "# **Quantum Neural Network (QNN) Classifier**\n",
    "\n",
    "This note is an example of using Photonic Analog (PA) QNN for binary classification. This is an application of the original work [\"Continuous Variable Quantum Neural Networks\"](https://arxiv.org/abs/1806.06871).\n",
    "\n",
    "Compared to Classical Neural Networks, PA QNNs have a reduced number of parameters to train and converge faster with fewer epochs. However, this is a quantum algorithm simulated on classical computers hence the training time for quantum circuits tend to be longder than classical models.\n",
    "\n",
    "The dataset used in this example can be found https://www.kaggle.com/datasets/shebrahimi/financial-distress.\n",
    "\n",
    "This file is organized in the following order:\n",
    "0. Install and import necessary packages\n",
    "1. Load and preprocess data (The data from Kaggle is saved as 'financial.csv'.\n",
    "2. Data encoding\n",
    "3. QNN model\n",
    "   * QNN layer\n",
    "   * QNN circuit\n",
    "   * Model building\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "\n",
    "For the open source repository, refer to https://github.com/qaintumai/quantum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhj9WZRYC8xf"
   },
   "source": [
    "## **0. Intall Packages**\n",
    "\n",
    "[Pennylane](https://pennylane.ai/) is a Python based quantum machine learning library by Xanadu. An old version is necessary for this example: v0.29.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tE3__8WZ868S",
    "outputId": "93f7628f-3555-4f7d-a30e-22215d2533f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\r\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\r\n",
      "pyfume 0.3.4 requires numpy==1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qqq torch torchvision\n",
    "!pip install -qqq pennylane\n",
    "!pip install -qqq pennylane-SF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It6FrGqWDFZz"
   },
   "source": [
    "## **0. Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fXgVhFJrnQmW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pennylane as qml\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cBEgVYWDKPd"
   },
   "source": [
    "## **1. Load and Preprocess Data**\n",
    "\n",
    "Data: Financial Distress\n",
    "Data points: 3,672\n",
    "Number of features: 83\n",
    "Label: real values indicating financial health\n",
    "\n",
    "For the purpose of this experiment, we are using only 100 data points for training and 20 for testing.\n",
    "\n",
    "data source: https://www.kaggle.com/datasets/shebrahimi/financial-distress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_GTnJWuNPFwJ"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load 'financial.csv' and preprocess the data.\n",
    "    Input: file path\n",
    "    Output: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(['Company', 'Time'], axis=1)\n",
    "    df.iloc[:, 0][df.iloc[:, 0] > 0.55] = 1.0\n",
    "    df.iloc[:, 0][df.iloc[:, 0] <= 0.55] = 0.0\n",
    "\n",
    "    y = df.iloc[:, 0]\n",
    "    X = df.iloc[:, 1:]\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    X_train = X[:100]\n",
    "    X_test = X[100:120]\n",
    "    y_train = y_scaled[:100]\n",
    "    y_test = y_scaled[100:120]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train = torch.tensor(X_train_scaled, requires_grad=True).float()\n",
    "    X_test = torch.tensor(X_test_scaled, requires_grad=False).float()\n",
    "    y_train = torch.tensor(np.reshape(y_train, y_train.shape[0]), requires_grad=False).float()\n",
    "    y_test = torch.tensor(np.reshape(y_test, y_test.shape[0]), requires_grad=False).float()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1oiuxWnPbZh",
    "outputId": "863701b6-4d14-4790-ee09-196b452cb531"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/pyq7sqpn54lf7hj_4295jgnm0000gn/T/ipykernel_22388/840034156.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/16/pyq7sqpn54lf7hj_4295jgnm0000gn/T/ipykernel_22388/840034156.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_preprocess_data('financial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxvvvhc_DT20"
   },
   "source": [
    "## **2. Data Encoding**\n",
    "\n",
    "This step converts classical data into a quantum state by using the data entries as parameters of the quantum gates.\n",
    "\n",
    "The data encoding gates used are Squeezing, Rotation, Beamsplitter, Displacement Gate, and Kerr Gate. Other gates under \"CV operators\" in the Pennylane package can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vWO3IB1iWFmz"
   },
   "outputs": [],
   "source": [
    "def data_encoding(x):\n",
    "    \"\"\"\n",
    "    This function converts classical data into a quantum state by using the data entries as parameters of the quantum gates.\n",
    "    Input: classical data (x)\n",
    "    No output: quantum state prepared to be operated on by the quantum layers\n",
    "    \"\"\"\n",
    "    num_features = len(x)\n",
    "    num_wires = 8\n",
    "\n",
    "    # Squeezing gates\n",
    "    for i in range(0, min(num_features, num_wires * 2), 2):\n",
    "        qml.Squeezing(x[i], x[i + 1], wires=i // 2)\n",
    "\n",
    "    # Beamsplitter gates\n",
    "    for i in range(num_wires - 1):\n",
    "        idx = num_wires * 2 + i * 2\n",
    "        if idx + 1 < num_features:\n",
    "            qml.Beamsplitter(x[idx], x[idx + 1], wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "    # Rotation gates\n",
    "    for i in range(num_wires):\n",
    "        idx = num_wires * 2 + (num_wires - 1) * 2 + i\n",
    "        if idx < num_features:\n",
    "            qml.Rotation(x[idx], wires=i)\n",
    "\n",
    "    # Displacement gates\n",
    "    for i in range(num_wires):\n",
    "        idx = num_wires * 2 + (num_wires - 1) * 2 + num_wires + i * 2\n",
    "        if idx + 1 < num_features:\n",
    "            qml.Displacement(x[idx], x[idx + 1], wires=i)\n",
    "\n",
    "    # Kerr gates\n",
    "    for i in range(num_wires):\n",
    "        idx = num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + i\n",
    "        if idx < num_features:\n",
    "            qml.Kerr(x[idx], wires=i)\n",
    "\n",
    "    # Squeezing gates (second set)\n",
    "    for i in range(0, min(num_features - (num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + num_wires), num_wires * 2), 2):\n",
    "        idx = num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + num_wires + i\n",
    "        if idx + 1 < num_features:\n",
    "            qml.Squeezing(x[idx], x[idx + 1], wires=i // 2)\n",
    "\n",
    "    # Rotation gates (second set)\n",
    "    for i in range(num_wires):\n",
    "        idx = num_wires * 2 + (num_wires - 1) * 2 + num_wires + num_wires * 2 + num_wires + num_wires * 2 + i\n",
    "        if idx < num_features:\n",
    "            qml.Rotation(x[idx], wires=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKuUlBY2D7My"
   },
   "source": [
    "## **3. QNN Model**\n",
    "To build a model, we need to\n",
    "* define a layer\n",
    "* build a circuit with the defined layer\n",
    "* build a model with the defined circuit.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC0LJy4pPK-G"
   },
   "source": [
    "### **3.1 QNN Layer**\n",
    "This in a faithful implementation of classical neural networks:\n",
    "* Weight matrix: Interferometer 1 + Squeezing + Interferometer 2\n",
    "* Bias addition: Displacement gate\n",
    "* Nonlinear activation function: Kerr gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "k-XQkaPgWJ6D"
   },
   "outputs": [],
   "source": [
    "def qnn_layer(v):\n",
    "    \"\"\"\n",
    "    This is one layer of QNN\n",
    "    Input: quantum parameters (v)\n",
    "    No output: quantum state prepared to be measured\n",
    "    \"\"\"\n",
    "    num_params = len(v)\n",
    "    num_wires = 8\n",
    "\n",
    "    # Interferometer 1\n",
    "    for i in range(num_wires - 1):\n",
    "        idx = i * 2\n",
    "        if idx + 1 < num_params:\n",
    "            theta = v[idx]\n",
    "            phi = v[idx + 1]\n",
    "            qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "    for i in range(num_wires):\n",
    "        idx = (num_wires - 1) * 2 + i\n",
    "        if idx < num_params:\n",
    "            qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "    # Squeezers\n",
    "    for i in range(num_wires):\n",
    "        idx = (num_wires - 1) * 2 + num_wires + i\n",
    "        if idx < num_params:\n",
    "            qml.Squeezing(v[idx], 0.0, wires=i)\n",
    "\n",
    "    # Interferometer 2\n",
    "    for i in range(num_wires - 1):\n",
    "        idx = (num_wires - 1) * 2 + num_wires + num_wires + i * 2\n",
    "        if idx + 1 < num_params:\n",
    "            theta = v[idx]\n",
    "            phi = v[idx + 1]\n",
    "            qml.Beamsplitter(theta, phi, wires=[i % num_wires, (i + 1) % num_wires])\n",
    "\n",
    "    for i in range(num_wires):\n",
    "        idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + i\n",
    "        if idx < num_params:\n",
    "            qml.Rotation(v[idx], wires=i)\n",
    "\n",
    "    # Bias addition\n",
    "    for i in range(num_wires):\n",
    "        idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + i\n",
    "        if idx < num_params:\n",
    "            qml.Displacement(v[idx], 0.0, wires=i)\n",
    "\n",
    "    # Non-linear activation function\n",
    "    for i in range(num_wires):\n",
    "        idx = (num_wires - 1) * 2 + num_wires + num_wires + (num_wires - 1) * 2 + num_wires + num_wires + i\n",
    "        if idx < num_params:\n",
    "            qml.Kerr(v[idx], wires=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvIfx9D1JEvK"
   },
   "source": [
    "**Weight Initializer**\n",
    "\n",
    "Randomly initialized values are used as initial parameters of the QNN circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hgxIT-LTWMdl"
   },
   "outputs": [],
   "source": [
    "def init_weights(layers, num_wires, active_sd=0.0001, passive_sd=0.1):\n",
    "    \"\"\"\n",
    "    This is a weight vector initializer.\n",
    "    Input: number of layers, number of wires\n",
    "    Output: concatenated weight vector\n",
    "    \"\"\"\n",
    "    M = (num_wires-1)*2 + num_wires  # Number of interferometer parameters\n",
    "\n",
    "    int1_weights = np.random.normal(size=[layers, M], scale=passive_sd)\n",
    "    s_weights = np.random.normal(size=[layers, num_wires], scale=active_sd)\n",
    "    int2_weights = np.random.normal(size=[layers, M], scale=passive_sd)\n",
    "    dr_weights = np.random.normal(size=[layers, num_wires], scale=active_sd)\n",
    "    k_weights = np.random.normal(size=[layers, num_wires], scale=active_sd)\n",
    "\n",
    "    weights = np.concatenate([int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gsoymu4JhDX"
   },
   "source": [
    "### **3.2 QNN Circuit**\n",
    "\n",
    "For building a PA circuit as opposed to a qubit-based circuit, we have to choose \"strawberryfields.fock\" as device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CqD_AY5hWRQJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 08:10:31.306986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "num_wires = 8\n",
    "num_basis = 2\n",
    "\n",
    "# select a device\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_wires, cutoff_dim=num_basis)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_nn(inputs, var):\n",
    "    \"\"\"\n",
    "    This is a quantum circuit composed of a data encoding circuit and a QNN circuit.\n",
    "    Input: classical data (inputs), quantum parameters (var)\n",
    "    Output: quantum state, converted to classical data after measurement\n",
    "    \"\"\"\n",
    "    # convert classical inputs into quantum states\n",
    "    data_encoding(inputs)\n",
    "\n",
    "    # iterative quantum layers\n",
    "    for v in var:\n",
    "        qnn_layer(v)\n",
    "\n",
    "    # measure the resulting state and return\n",
    "    return qml.expval(qml.X(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2UWYAG5PlBR"
   },
   "source": [
    "### **3.3 Model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5OoLbvMyP5yI"
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "def get_model(num_wires, num_layers):\n",
    "    \"\"\"\n",
    "    This is a model building function.\n",
    "    Input: number of modes, number of layers\n",
    "    Output: PyTorch model\n",
    "    \"\"\"\n",
    "    weights = init_weights(num_layers, num_wires)\n",
    "    shape_tup = weights.shape\n",
    "    weight_shapes = {'var': shape_tup}\n",
    "    qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
    "    model = torch.nn.Sequential(qlayer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qGmhPxDVSMeB"
   },
   "outputs": [],
   "source": [
    "model = get_model(num_wires, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bD9VFed3QTDa"
   },
   "source": [
    "## **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S3eluEwDQBAo"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, batch_size=5, epochs=6):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for xs, ys in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x = model(xs).float()\n",
    "            y = ys.float()\n",
    "            loss = loss_fn(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(data_loader)\n",
    "        print(f\"Average loss over epoch {epoch + 1}: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGPJ2eHmQfwf",
    "outputId": "b50ca368-73f5-4ba3-8bbd-d21a19ae7f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.5400\n",
      "Average loss over epoch 2: 0.5400\n",
      "Average loss over epoch 3: 0.5400\n"
     ]
    }
   ],
   "source": [
    "train_model(model, X_train, y_train, batch_size=5, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUoLVYZfQhso"
   },
   "source": [
    "## **5. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aJKoK9LBQcyk"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model(X_test).detach().numpy()\n",
    "    y_test = y_test.numpy()\n",
    "    correct = [1 if p == p_true else 0 for p, p_true in zip(y_pred, y_test)]\n",
    "    accuracy = sum(correct) / len(y_test)\n",
    "    print(f\"Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukFClVII82fH",
    "outputId": "6a7e2bb6-5f55-412b-8d78-122c07d79c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "addf9ebabba077b7079118deca383f86ec5c88236429b04c233b7a7a20903763"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
